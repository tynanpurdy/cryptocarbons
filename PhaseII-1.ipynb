{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GJ4Xt1uf1LT7"
   },
   "source": [
    "# Final Project Phase 2 Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tb9oVjpRDswQ"
   },
   "source": [
    "# Data Collection and Cleaning\n",
    "You are required to provide data collection and cleaning for the three (3) minimum datasets. Create a function for each of the following sections that reads or scrapes data from a file or website, manipulate and cleans the parsed data, and writes the cleaned data into a new file. \n",
    "\n",
    "Make sure your data cleaning and manipulation process is not too simple. Performing complex manipulation and using modules not taught in class shows effort, which will increase the chance of receiving full credit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Dp7Pm-Suh3d"
   },
   "source": [
    "## Data Sources\n",
    "Include sources (as links) to your datasets. Add any additional data sources if needed. Clearly indicate if a data source is different from one submitted in your Phase I, as we will check that it satisfies the requirements.\n",
    "*   Downloaded Dataset Source: [Global Power Plant Database](https://datasets.wri.org/dataset/globalpowerplantdatabase) and [Global Power Plant Emissions Database](http://meicmodel.org/?page_id=91&lang=en)\n",
    "*   Web Collection #1 Source: [WhatToMine Coins](https://whattomine.com/coins.json) and [WhatToMine GPUs](https://whattomine.com/gpus)\n",
    "*   Web Collection #2 Source: [CoinGecko](https://www.coingecko.com/en/apiBlo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9mRjxZDbE1tj"
   },
   "source": [
    "## Downloaded Dataset Requirement\n",
    "\n",
    "Fill in the predefined functions with your data scraping/parsing code. You may modify/rename each function as you seem fit, but you must provide at least 3 separate functions that clean each of your required datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from pprint import pprint\n",
    "import requests, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0p5xxmqzFGrO"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GENERATION_MW</th>\n",
       "      <th>CO2 Emissions (Mg)</th>\n",
       "      <th>SO2 Emissions (Mg)</th>\n",
       "      <th>NOx Emissions (Mg)</th>\n",
       "      <th>PM2.5 Emissions (Mg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>COAL</th>\n",
       "      <td>9.960694e+06</td>\n",
       "      <td>8.880799e+09</td>\n",
       "      <td>2.973419e+07</td>\n",
       "      <td>1.848038e+07</td>\n",
       "      <td>2.508320e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAS</th>\n",
       "      <td>6.304916e+06</td>\n",
       "      <td>2.518846e+09</td>\n",
       "      <td>5.228739e+04</td>\n",
       "      <td>3.440040e+06</td>\n",
       "      <td>4.144760e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HYDRO</th>\n",
       "      <td>3.755360e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WIND</th>\n",
       "      <td>7.094421e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OIL</th>\n",
       "      <td>5.360917e+05</td>\n",
       "      <td>7.370139e+08</td>\n",
       "      <td>8.689335e+06</td>\n",
       "      <td>2.723445e+06</td>\n",
       "      <td>9.304416e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOLAR</th>\n",
       "      <td>3.486002e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GEOTHERMAL</th>\n",
       "      <td>6.083382e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIOMASS</th>\n",
       "      <td>3.368912e+04</td>\n",
       "      <td>1.196067e+08</td>\n",
       "      <td>1.792376e+05</td>\n",
       "      <td>1.744930e+05</td>\n",
       "      <td>3.713316e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OTHER</th>\n",
       "      <td>3.011469e+06</td>\n",
       "      <td>2.749785e+08</td>\n",
       "      <td>1.500827e+05</td>\n",
       "      <td>3.382073e+05</td>\n",
       "      <td>1.042250e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            GENERATION_MW  CO2 Emissions (Mg)  SO2 Emissions (Mg)  \\\n",
       "COAL         9.960694e+06        8.880799e+09        2.973419e+07   \n",
       "GAS          6.304916e+06        2.518846e+09        5.228739e+04   \n",
       "HYDRO        3.755360e+06        0.000000e+00        0.000000e+00   \n",
       "WIND         7.094421e+05        0.000000e+00        0.000000e+00   \n",
       "OIL          5.360917e+05        7.370139e+08        8.689335e+06   \n",
       "SOLAR        3.486002e+05        0.000000e+00        0.000000e+00   \n",
       "GEOTHERMAL   6.083382e+04        0.000000e+00        0.000000e+00   \n",
       "BIOMASS      3.368912e+04        1.196067e+08        1.792376e+05   \n",
       "OTHER        3.011469e+06        2.749785e+08        1.500827e+05   \n",
       "\n",
       "            NOx Emissions (Mg)  PM2.5 Emissions (Mg)  \n",
       "COAL              1.848038e+07          2.508320e+06  \n",
       "GAS               3.440040e+06          4.144760e+04  \n",
       "HYDRO             0.000000e+00          0.000000e+00  \n",
       "WIND              0.000000e+00          0.000000e+00  \n",
       "OIL               2.723445e+06          9.304416e+04  \n",
       "SOLAR             0.000000e+00          0.000000e+00  \n",
       "GEOTHERMAL        0.000000e+00          0.000000e+00  \n",
       "BIOMASS           1.744930e+05          3.713316e+04  \n",
       "OTHER             3.382073e+05          1.042250e+04  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def global_power():\n",
    "  # IMPORT FILES\n",
    "  generation_path = \"data\\global-power-plants\\global_power_plant_database.csv\"\n",
    "  emission_path = \"data\\global-power-plants\\global_power_emissions_database.xlsx\"\n",
    "  \n",
    "  # power generation csv\n",
    "  with open(generation_path, encoding='utf8') as fin:\n",
    "    ppg = pd.read_csv(fin, low_memory=False)\n",
    "  \n",
    "  # power plant emissions xlsx\n",
    "  ppe = pd.read_excel(emission_path, sheet_name='GPED_v1.0_Plant Level', skiprows=0, header=1)\n",
    "\n",
    "  # removing unwanted data\n",
    "  unwanted_columns = ['latitude',\n",
    "                      'longitude',\n",
    "                      'other_fuel1',\n",
    "                      'other_fuel2',\n",
    "                      'other_fuel3',\n",
    "                      'commissioning_year',\n",
    "                      'gppd_idnr',\n",
    "                      'owner',\n",
    "                      'source',\n",
    "                      'url',\n",
    "                      'geolocation_source',\n",
    "                      'wepp_id',\n",
    "                      'year_of_capacity_data',\n",
    "                      'generation_data_source',\n",
    "                      'generation_gwh_2018',\n",
    "                      'generation_gwh_2019',\n",
    "                      'estimated_generation_note_2013',\n",
    "                      'estimated_generation_note_2014',\n",
    "                      'estimated_generation_note_2015',\n",
    "                      'estimated_generation_note_2016',\n",
    "                      'estimated_generation_note_2017']\n",
    "  ppg.drop(unwanted_columns, axis=1, inplace=True)\n",
    "\n",
    "  unwanted_columns = ['No.', 'Number of Units', 'Total Plant Installed Capacity (MW)']\n",
    "  ppe.drop(unwanted_columns, axis=1, inplace=True)\n",
    "\n",
    "  # AGGREGATING DATA\n",
    "  avgs = ['generation_gwh_2013',\n",
    "          'generation_gwh_2014',\n",
    "          'generation_gwh_2015',\n",
    "          'generation_gwh_2016',\n",
    "          'generation_gwh_2017']\n",
    "  ppg['AVG_GENERATION'] = ppg[avgs].mean(axis=1)\n",
    "\n",
    "  avgs = ['estimated_generation_gwh_2013',\n",
    "          'estimated_generation_gwh_2014',\n",
    "          'estimated_generation_gwh_2015',\n",
    "          'estimated_generation_gwh_2016',\n",
    "          'estimated_generation_gwh_2017']\n",
    "  ppg['AVG_EST_GENERATION'] = ppg[avgs].mean(axis=1)\n",
    "\n",
    "  # merge the two average columns into a single column\n",
    "  ppg['GENERATION_MW'] = ppg.apply(lambda x : np.fmax(x['AVG_GENERATION'], x['AVG_EST_GENERATION']), axis=1)\n",
    "\n",
    "  # remove unaggregated columns\n",
    "  unwanted_columns = ['AVG_GENERATION',\n",
    "                      'AVG_EST_GENERATION',\n",
    "                      'generation_gwh_2013',\n",
    "                      'generation_gwh_2014',\n",
    "                      'generation_gwh_2015',\n",
    "                      'generation_gwh_2016',\n",
    "                      'generation_gwh_2017',\n",
    "                      'estimated_generation_gwh_2013',\n",
    "                      'estimated_generation_gwh_2014',\n",
    "                      'estimated_generation_gwh_2015',\n",
    "                      'estimated_generation_gwh_2016',\n",
    "                      'estimated_generation_gwh_2017']\n",
    "  ppg.drop(unwanted_columns, axis=1, inplace=True)\n",
    "\n",
    "  # merge rows by fuel type\n",
    "  generation_dist = ppg.groupby('primary_fuel')['GENERATION_MW'].sum().sort_values(ascending=False)\n",
    "  emission_dist = ppe.groupby('Fuel Types').aggregate({'CO2 Emissions (Mg)':'sum',\n",
    "                                                       'SO2 Emissions (Mg)':'sum',\n",
    "                                                       'NOx Emissions (Mg)':'sum',\n",
    "                                                       'PM2.5 Emissions (Mg)':'sum'})\n",
    "\n",
    "  # COMBINING TABLES\n",
    "  generation_dist.index = generation_dist.index.str.upper()\n",
    "  generation_dist.drop('WAVE AND TIDAL', axis=0, inplace=True)\n",
    "  gen_other = ['PETCOKE','WASTE','COGENERATION','STORAGE','NUCLEAR']\n",
    "  generation_dist['OTHER'] = generation_dist[gen_other].sum(axis=0)\n",
    "  generation_dist.drop(gen_other, axis=0, inplace=True)\n",
    "  emission_dist = emission_dist.rename(index={'NG':'GAS'})\n",
    "\n",
    "  power = pd.concat([generation_dist, emission_dist], axis=1)\n",
    "  power = power.fillna(0)\n",
    "\n",
    "  return power\n",
    "\n",
    "############ Function Call ############\n",
    "global_power()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "794L4vGXFdYw"
   },
   "source": [
    "## Web Collection Requirement \\#1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "vXwpJObDFiWM"
   },
   "outputs": [],
   "source": [
    "def web_scrape(): #overarching function - data frame doesnt present as nicely as when on its own which is why the code is broken up \n",
    "    #below. Not sure if we need just one function because that works just as well up until you call function which returns None\n",
    "\n",
    "    hashlist = []\n",
    "    hashdict = {}\n",
    "    url = requests.get('https://whattomine.com/gpus')\n",
    "    soup = BeautifulSoup(url.text, 'html.parser')\n",
    "    for hasher in soup.find_all('div',{'class' :'position-relative'}):\n",
    "        for h in hasher.stripped_strings:\n",
    "            hashlist.append(h)\n",
    "            hashlist2=  hashlist[::2]\n",
    "            hashdict['Hashrate(Millions of Hash Per Sec)'] = [z for z in hashlist2] #creates a dict that connects to a list of all the HashRates of GPUs for easy iteration when creating visuals\n",
    "    print(hashdict)\n",
    "\n",
    "    revlist = []\n",
    "    revdict = {}\n",
    "    for rev in soup.find_all('td',{'class':'text-right table-success font-weight-bold'}):\n",
    "        for r in rev.stripped_strings:\n",
    "            revlist.append(r)\n",
    "            revdict[\"24Hour Revenue\"] = [z for z in revlist]\n",
    "    print(revdict) #creates a dict that connects to a list of all the HashRates of GPUs for easy iteration when creating visuals\n",
    "    \n",
    "    namelist = []\n",
    "    namedict = {}\n",
    "    for name in soup.find_all('td'):\n",
    "        for n in name.stripped_strings:\n",
    "            namelist.append(n)\n",
    "            namelist2 = namelist[1:64:16]\n",
    "            namelist2+=namelist[66:99:16]\n",
    "            namelist2+=namelist[115:175:16]\n",
    "            namelist2+=namelist[180:181]\n",
    "            namelist2+=namelist[196:260:16]\n",
    "            namelist2+=namelist[261:262]\n",
    "            namelist2+=namelist[277:325:16]\n",
    "            namelist2+=namelist[326:343:16]\n",
    "            namelist2+=namelist[359:377:17]\n",
    "            namelist2+=namelist[392:521:16]\n",
    "            namelist2+=namelist[537:650:16]\n",
    "            #no identifiable iteration order, easier for me to do it mathematically this way\n",
    "            namedict[\"GPU Model\"] = [z for z in namelist2]\n",
    "    print(namedict)\n",
    "    \n",
    "    fulldict = {}\n",
    "    for i in range(len(namelist2)):\n",
    "        fulldict[namelist2[i]] = {\"Hashrate(Millions of Hash Per Sec)\":hashlist2[i],\"24Hour Revenue\": revlist[i]}\n",
    "    print(fulldict) # this dictionary matches GPU model to the hash rate and 24 hour revenue\n",
    "    \n",
    "    data = []\n",
    "    data.append(hashlist2)\n",
    "    data.append(revlist)\n",
    "    df = pd.DataFrame(data, index= ['Hashrate (Millions of Hashes Per Sec)','24 Hour Revenue'], columns = namelist2).T\n",
    "    return df #creates a data frame with the columns as GPU name and the index as the description \n",
    "\n",
    "############ Function Call ############\n",
    "web_scrape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eDD6sMsCXRxc"
   },
   "source": [
    "## Web Collection Requirement \\#2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "HAkUOqMgXQJG"
   },
   "outputs": [],
   "source": [
    "def web_parser2():\n",
    "  pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############ Function Call ############\n",
    "web_parser2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ezovwa1tp0we"
   },
   "source": [
    "## Additional Dataset Parsing/Cleaning Functions\n",
    "\n",
    "Write any supplemental (optional) functions here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "f4-s72RNuKLR"
   },
   "outputs": [],
   "source": [
    "def extra_source1():\n",
    "    pass\n",
    "\n",
    "    \n",
    "############ Function Call ############\n",
    "extra_source1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "yB3qXt_XuY7b"
   },
   "outputs": [],
   "source": [
    "# Define further extra source functions as necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uttEYrm9US5s"
   },
   "source": [
    "# Inconsistencies\n",
    "For each inconsistency (NaN, null, duplicate values, empty strings, etc.) you discover in your datasets, write at least 2 sentences stating the significance, how you identified it, and how you handled it.\n",
    "\n",
    "1. \n",
    "\n",
    "2. \n",
    "\n",
    "3. \n",
    "\n",
    "4. (if applicable)\n",
    "\n",
    "5. (if applicable)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PhaseII.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "0635a69235b8be13852489ad251e8c349647cdc922a670444a76820170957137"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
